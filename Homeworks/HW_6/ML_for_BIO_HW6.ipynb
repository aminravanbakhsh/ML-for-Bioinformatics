{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW5_P2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0LKk6KmvGcX"
      },
      "source": [
        "# CE-40550: Machine Learning for Bioinformatic\n",
        "## HW5 - Generative Adversarial Networks\n",
        "#### 34 Points\n",
        "\n",
        "---\n",
        "\n",
        "Name:\n",
        "\n",
        "Student No.:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C2E7edUvbye"
      },
      "source": [
        "### 1) Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T7DEwSwuWsF"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFJgoMQJIN88"
      },
      "source": [
        "### 2) Auxiliary Modules\n",
        "These are some useful modules that you can use. Please read them carefully and use them wherever you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWriUWVFIKR8"
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "  \"\"\"\n",
        "  This module reshapes its input to `new_shape`\n",
        "  \"\"\"\n",
        "  def __init__(self, new_shape):\n",
        "    super().__init__()\n",
        "    self.new_shape = new_shape\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x.view(-1, *self.new_shape)\n",
        "\n",
        "class NoiseGenerator(nn.Module):\n",
        "  \"\"\"\n",
        "  This module generates `n` noises with `z_dim` dim from Normal distribution.\n",
        "  \"\"\"\n",
        "  def __init__(self, z_dim):\n",
        "    super().__init__()\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "  def forward(self, n):\n",
        "    noise = torch.randn(n, *self.z_dim).to(device)\n",
        "    return noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH_eLvHLxgo7"
      },
      "source": [
        "### 3) Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8JTJPtnxjFL"
      },
      "source": [
        "def vector_linspace(start, end, steps):\n",
        "  \"\"\"\n",
        "  Vector version of torch linspace\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  for dim in range(start.shape[0]):\n",
        "    result.append(torch.linspace(start[dim], end[dim], steps))\n",
        "  result = torch.stack(result, dim=1).to(device)\n",
        "  return result\n",
        "  \n",
        "def mnist_show(image_batch, rows=1):\n",
        "  \"\"\"\n",
        "  This function gets multiple MNIST images and plots them in the given number of rows.\n",
        "  \"\"\"\n",
        "  image_batch = image_batch.detach().cpu()\n",
        "  image_batch = image_batch.view(-1, 28, 28)\n",
        "  image_batch = image_batch.numpy()\n",
        "\n",
        "  cols = np.ceil(image_batch.shape[0] / rows)\n",
        "  plt.rcParams['figure.figsize'] = (cols, rows)\n",
        "  \n",
        "  for i in range(image_batch.shape[0]):\n",
        "      plt.subplot(rows, cols, i + 1)\n",
        "      plt.imshow(image_batch[i], cmap=\"gray\", vmin=0, vmax=1)\n",
        "      plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def mnist_visulization_helper_fn(trainer):\n",
        "  \"\"\"\n",
        "  Generates fake samples and plots them for you.\n",
        "  \"\"\"\n",
        "  _, fake_samples = trainer.generate_samples(30)\n",
        "  mnist_show(fake_samples, 3)\n",
        "\n",
        "def show_interpolations(trainer, n_rows, n_cols):\n",
        "    \"\"\"\n",
        "    Shows image interpolation (grid of [`n_rows`, `n_cols`]) in input noise space.\n",
        "    \"\"\"\n",
        "    anchor_noises = trainer.noise_generator(4)\n",
        "    left_column = vector_linspace(anchor_noises[0], anchor_noises[1], n_rows)\n",
        "    right_column = vector_linspace(anchor_noises[2], anchor_noises[3], n_rows)\n",
        "    rows = []\n",
        "    for i in range(n_rows):\n",
        "      rows.append(vector_linspace(left_column[i], right_column[i], n_cols))\n",
        "    noises = torch.stack(rows, dim=0).view(n_rows * n_cols, -1)\n",
        "    with torch.no_grad():\n",
        "      fake_imgs = trainer.generator(noises)\n",
        "    mnist_show(fake_imgs, n_rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUErPdG4wjyC"
      },
      "source": [
        "### 4) Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx3HVdi4vvS_"
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "BATCH_SIZE = 256\n",
        "device = torch.device(torch.cuda.current_device()) if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "mnist_dataset_kwargs = {\n",
        "    'download': True,\n",
        "    'transform': transforms.Compose([\n",
        "                                     transforms.ToTensor(),\n",
        "                                     lambda img: img * 2 - 1\n",
        "                                     ])\n",
        "}\n",
        "\n",
        "mnist_dataloader_kwargs = {\n",
        "    'batch_size': BATCH_SIZE, \n",
        "    'pin_memory': True,\n",
        "    'num_workers': 4,\n",
        "    'shuffle': True\n",
        "}\n",
        "\n",
        "mnist_train_dataset = datasets.MNIST('./data', train=True, **mnist_dataset_kwargs)\n",
        "mnist_test_dataset = datasets.MNIST('./data', train=False, **mnist_dataset_kwargs)\n",
        "\n",
        "\n",
        "mnist_train_dataloader = torch.utils.data.DataLoader(mnist_train_dataset, sampler= None, **mnist_dataloader_kwargs)\n",
        "mnist_test_dataloader = torch.utils.data.DataLoader(mnist_test_dataset, sampler= None, **mnist_dataloader_kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH2fh8CFxLjX"
      },
      "source": [
        "temp = torch.stack([mnist_train_dataset[i][0] for i in range(30)], dim=0)\n",
        "mnist_show(temp, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WQlqV-D2jO2"
      },
      "source": [
        "### 5) Defining Models (6 points)\n",
        "In this section you are going to define generator and discriminator models. Also you should define a module to generate noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iNZVeyx2h-N"
      },
      "source": [
        "  # Generator part\n",
        "#################### Problem 16 (3 points) ####################\n",
        "# 1) Define `mnist_noise_generator`.\n",
        "# 2) Define `mnist_generator` network.\n",
        "#    Use `LeakyReLU` for intermediate layers.\n",
        "#    Use `Tanh` for the last layer.\n",
        "#    Use convolution layers.\n",
        "#    Can use batch norm, dropout, ...\n",
        "####################################################\n",
        "mnist_noise_generator = NoiseGenerator(pass)\n",
        "\n",
        "mnist_generator = nn.Sequential(\n",
        "    pass\n",
        ")\n",
        "####################### End ########################\n",
        "\n",
        "# Discriminator part\n",
        "#################### Problem 17 (3 points) ####################\n",
        "# 1) Define `mnist_discriminator` network.\n",
        "#    Use `LeakyReLU` for intermediate layers.\n",
        "#    Use `Linear` for the last layer.\n",
        "#    Use convolution layers.\n",
        "#    Can use batch norm, dropout, ...\n",
        "####################################################\n",
        "mnist_discriminator = nn.Sequential(\n",
        "    pass\n",
        ")\n",
        "####################### End ########################\n",
        "\n",
        "mnist_generator = mnist_generator.to(device)\n",
        "mnist_discriminator = mnist_discriminator.to(device)\n",
        "\n",
        "print(mnist_generator)\n",
        "print(mnist_discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTwPxvqyx_SY"
      },
      "source": [
        "### 6) Training Loop (14 points)\n",
        "In this section you are going to complete the training loop structure code.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWG7RsT8xPi5"
      },
      "source": [
        "class GANTrainer:\n",
        "  \"\"\"\n",
        "  This class wraps the GAN training structure.\n",
        "\n",
        "  Some arguments:\n",
        "  `visualization_helper_fn`: Used to visualize model outputs at the end of each epoch.\n",
        "  `G_loss_mode`: `{\"logD\" | \"log(1-D)\"}` Controls the loss function of the `generator`.\n",
        "  `generator`: The generator.\n",
        "  `discriminator`: The discriminator. The last layer is a LINEAR layer.\n",
        "  \"\"\"\n",
        "  def __init__(self, train_dataloader:torch.utils.data.DataLoader, test_dataloader:torch.utils.data.DataLoader,\n",
        "               noise_generator:NoiseGenerator, generator:nn.Module, discriminator:nn.Module,\n",
        "               G_lr, D_lr,\n",
        "               visualization_helper_fn, G_loss_mode):\n",
        "    self.train_dataloader = train_dataloader\n",
        "    self.test_dataloader = test_dataloader\n",
        "\n",
        "    self.noise_generator = noise_generator.to(device)\n",
        "    self.generator = generator.to(device)\n",
        "    self.discriminator = discriminator.to(device)\n",
        "\n",
        "    self.visualization_helper_fn = visualization_helper_fn\n",
        "    self.G_loss_mode = G_loss_mode\n",
        "    \n",
        "    #################### Problem 01 (1 points) ####################\n",
        "    # Define Adam optimizers with `G_lr` and `D_lr` learning rates.\n",
        "    ####################################################\n",
        "    self.opt_G = pass\n",
        "    self.opt_D = pass\n",
        "    ####################### End ########################\n",
        "\n",
        "  def generate_samples(self, n):\n",
        "    \"\"\"\n",
        "    This function generates `n` samples.\n",
        "    \"\"\"\n",
        "    #################### Problem 02 (1 points) ####################\n",
        "    # 1) Generate `n` noises\n",
        "    # 1) Transform noises to samples\n",
        "    ####################################################\n",
        "    noise = pass\n",
        "    fake_samples = pass\n",
        "    ####################### End ########################\n",
        "    return noise, fake_samples\n",
        "\n",
        "  def G_step(self, n):\n",
        "    \"\"\"\n",
        "    This function calculates `generator`'s loss for `n` samples.\n",
        "    \"\"\"\n",
        "    #################### Problem 03 (1 points) ####################\n",
        "    # 1) Generate `n` fake samples. put them in `x_fake`\n",
        "    # 2) Compute discriminator `logits` for generated samples\n",
        "    ####################################################\n",
        "    x_fake = pass\n",
        "    logits = pass\n",
        "    ####################### End ########################\n",
        "\n",
        "    if self.G_loss_mode == 'logD':\n",
        "      #################### Problem 04 (2 points) ####################\n",
        "      # Compute the `generator`'s loss when using `logD` as an objective.\n",
        "      # `loss = mean(...)`\n",
        "      #\n",
        "      # CAUTION!!!!! --->>>> PAY ATTENTION TO THE SIGN OF LOSS\n",
        "      ####################################################\n",
        "      criterion = pass\n",
        "      loss = pass\n",
        "      ####################### End ########################\n",
        "\n",
        "    elif self.G_loss_mode == 'log(1-D)':\n",
        "      #################### Problem 05 (2 points) ####################\n",
        "      # Compute the `generator`'s loss when using `log(1-D)` as an objective.\n",
        "      # `loss = mean(...)`\n",
        "      #\n",
        "      # CAUTION!!!!! --->>>> PAY ATTENTION TO THE SIGN OF LOSS\n",
        "      ####################################################\n",
        "      criterion = pass\n",
        "      loss = pass\n",
        "      ####################### End ########################\n",
        "\n",
        "    else:\n",
        "      raise BaseException('Invalid generator train mode!!')\n",
        "      \n",
        "    return loss, x_fake\n",
        "\n",
        "  def D_step(self, x_real):\n",
        "    \"\"\"\n",
        "    This function calculates `discriminator`'s loss for `x_real` and `x_fake`.\n",
        "    \"\"\"\n",
        "    #################### Problem 06 (1 points) ####################\n",
        "    # 1) Generate `n` fake samples. n is equal to length of real samples\n",
        "    #  put them in `x_fake`\n",
        "    # 2) Detach the generated samples.\n",
        "    ####################################################\n",
        "    x_fake = pass\n",
        "    ####################### End ########################\n",
        "\n",
        "    #################### Problem 07 (2 points) ####################\n",
        "    # Compute discriminator `loss` for `x_real` and `x_fake`. \n",
        "    # `loss = mean(...)`\n",
        "    ####################################################\n",
        "    loss = pass\n",
        "    ####################### End ########################\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def train_loop(self, epoch, G_update_times, D_update_times):\n",
        "    \"\"\"\n",
        "    This function iterates over `train_dataloader` and trains \n",
        "    `generator` and `discriminator` for ONE epoch.\n",
        "\n",
        "    Some arguments: \\n\n",
        "    `G_update_times`: how many times to update `generator` on each batch \\n\n",
        "    `D_update_times`: how many times to update `discriminator` on each batch \\n\n",
        "    \"\"\"\n",
        "    train_G_loss = 0\n",
        "    train_D_loss = 0\n",
        "\n",
        "    for batch_idx, (x, _) in enumerate(tqdm(self.train_dataloader)):\n",
        "      x = x.to(device)\n",
        "\n",
        "      for _ in range(D_update_times):\n",
        "        #################### Problem 08 (1 points) ####################\n",
        "        # 1) Put `generator` and `discriminator` in appropriate mode\n",
        "        # 2) Zero out `opt_D`'s gradients\n",
        "        # 3) Compute `discriminator`'s loss (`D_loss`); use `D_step`\n",
        "        # 4) Backpropagate `D_loss`\n",
        "        # 5) Update ``discriminator` parameters\n",
        "        ####################################################\n",
        "        pass\n",
        "        D_loss = pass\n",
        "        pass\n",
        "        ####################### End ########################\n",
        "\n",
        "      for _ in range(G_update_times):\n",
        "        #################### Problem 09 (1 points) ####################\n",
        "        # 1) Put `generator` and `discriminator` in appropriate mode\n",
        "        # 2) Zero out `opt_G`'s gradients\n",
        "        # 3) Compute `generator`'s loss (`G_loss`); use `G_step`\n",
        "        # 4) Backpropagate `G_loss`\n",
        "        # 5) Update `generator` parameters\n",
        "        ####################################################\n",
        "        pass\n",
        "        G_loss = pass\n",
        "        pass\n",
        "        ####################### End ########################\n",
        "      \n",
        "      train_D_loss += D_loss.item() * x.shape[0]\n",
        "      train_G_loss += G_loss.item() * x.shape[0]\n",
        "\n",
        "      if batch_idx % LOG_INTERVAL == 0:\n",
        "          print('Train | Epoch: {} [{}/{}]\\t\\tD-Loss: {:.6f}\\tG-Loss: {:.6f}'\n",
        "          .format(epoch, batch_idx * len(x), len(self.train_dataloader) * BATCH_SIZE, D_loss, G_loss))\n",
        "\n",
        "    train_D_loss /= len(self.train_dataloader) * BATCH_SIZE\n",
        "    train_G_loss /= len(self.train_dataloader) * BATCH_SIZE\n",
        "    \n",
        "    print('====> Train | Epoch: {} \\t | \\tAverage D-loss: {:.4f} \\t | \\tAverage G-loss: {:.4f}'.format(epoch, train_D_loss, train_G_loss,))\n",
        "    return train_G_loss, train_D_loss\n",
        "  \n",
        "  def test(self):\n",
        "    \"\"\"\n",
        "    This function iterates over `test_dataloader` and\n",
        "    reports `generator` and `discriminator` losses.\n",
        "    \"\"\"\n",
        "    self.discriminator.eval()\n",
        "    self.generator.eval()\n",
        "\n",
        "    test_G_loss = 0\n",
        "    test_D_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, _ in self.test_dataloader:\n",
        "        x = x.to(device)\n",
        "\n",
        "        #################### Problem 10 (1 points) ####################\n",
        "        # 1) Put `generator` in `eval` mode\n",
        "        # 2) Put `discriminator` in `train` mode\n",
        "        # 4) Compute `discriminator`'s loss; use `D_step`\n",
        "        ####################################################\n",
        "        pass\n",
        "        D_loss = pass\n",
        "        ####################### End ########################\n",
        "\n",
        "        #################### Problem 11 (1 points) ####################\n",
        "        # 1) Put `generator` in `train` mode\n",
        "        # 2) Put `discriminator` in `eval` mode\n",
        "        # 4) Compute `generator`'s loss; use `G_step(n)` where `n = x.shape[0]`\n",
        "        ####################################################\n",
        "        pass\n",
        "        G_loss = pass\n",
        "        ####################### End ########################\n",
        "\n",
        "        test_D_loss += D_loss.item() * x.shape[0]\n",
        "        test_G_loss += G_loss.item() * x.shape[0]\n",
        "\n",
        "            \n",
        "    test_D_loss /= len(self.test_dataloader) * BATCH_SIZE\n",
        "    test_G_loss /= len(self.test_dataloader) * BATCH_SIZE\n",
        "    \n",
        "    print('====> Test | Average D-loss: {:.4f} \\t | \\tAverage G-loss: {:.4f}'.format(test_D_loss, test_G_loss,))\n",
        "    return test_G_loss, test_D_loss\n",
        "\n",
        "  def run(self, n_epoch, G_update_times=1, D_update_times=1):\n",
        "    \"\"\"\n",
        "    This function will optimize parameters of `generator` and `discriminator`\n",
        "    for `n_epoch` epochs on `train_dataloader` dataset and validate it on\n",
        "    `test_dataloader`. At the end of each epoch, `visualization_helper_fn`\n",
        "    will be called to visualize the GAN behavior.\n",
        "\n",
        "\n",
        "    Some arguments: \\n\n",
        "    `G_update_times`: how many times to update `generator` on each batch \\n\n",
        "    `D_update_times`: how many times to update `discriminator` on each batch \\n\n",
        "    \"\"\"\n",
        "    \n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        self.train_loop(epoch, G_update_times, D_update_times)\n",
        "        self.test()\n",
        "        self.visualization_helper_fn(self)   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK5z8HidLZRp"
      },
      "source": [
        "### 7) Run GAN (10 ponits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGDyuRV9uHxV"
      },
      "source": [
        "In this section, you will train a GAN for mnist dataset. Tune the learning rates for the generator and the discriminator, choose the loss function for the generator network and determine the number of epochs and the generator and discriminator's update times in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gFqs_ogLdp0"
      },
      "source": [
        "LOG_INTERVAL = 50\n",
        "#################### Problem 18 (1 points) ####################\n",
        "# Tune `generator` and `discriminator` learning rates\n",
        "# and also the `G_LOSS_MODE`.\n",
        "####################################################\n",
        "MNIST_G_LEARNING_RATE = pass\n",
        "MNIST_D_LEARNING_RATE = pass\n",
        "G_LOSS_MODE = pass\n",
        "####################### End ########################\n",
        "\n",
        "mnist_trainer = GANTrainer(mnist_train_dataloader, mnist_test_dataloader,\n",
        "                           mnist_noise_generator, mnist_generator, mnist_discriminator,\n",
        "                           MNIST_G_LEARNING_RATE, MNIST_D_LEARNING_RATE,\n",
        "                           mnist_visulization_helper_fn, G_LOSS_MODE)\n",
        "\n",
        "#################### Problem 19 (1 points) ####################\n",
        "# Tune `n_epoch`, `G_update_times` and `D_update_times`\n",
        "####################################################\n",
        "mnist_trainer.run(n_epoch=pass, G_update_times=pass, D_update_times=pass)\n",
        "####################### End ########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZT2X6nU2BCE"
      },
      "source": [
        "Question 1) What will happen if the number of updates of discriminator network is much higher than the number of updates of generator network in each epoch? (2 points)\n",
        "\n",
        "Your answer:\n",
        "\n",
        "Question 2) What will happen if the number of updates of generator network is much higher than the number of updates of discriminator network in each epoch? (2 points)\n",
        "\n",
        "Your answer:\n",
        "\n",
        "You can write your answers in persian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myDWvCgCLppU"
      },
      "source": [
        "### 8) Final Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJC6ft3WLrQG"
      },
      "source": [
        "mnist_visulization_helper_fn(mnist_trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_0-tHIELyLp"
      },
      "source": [
        "### 10) Interpolation (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoT2Uw8L08-"
      },
      "source": [
        "show_interpolations(mnist_trainer, 10, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_C-K237kaOg"
      },
      "source": [
        "Question 3) Describe what is happening above (4 points). You can write your answer in persian.\n",
        "\n",
        "Your Answer:"
      ]
    }
  ]
}